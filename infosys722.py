# -*- coding: utf-8 -*-
"""InfoSys722.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QsOD5J3pBmI2FkQcxz4Y1GUEDRC6DwM6
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn.metrics import accuracy_score,confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("/content/GlobalLandTemperaturesByCountry.csv")
df

#To Make all the values standardise, converting dt column to the datetime format
df['dt'] = pd.to_datetime(df['dt'])

#Checking if there any missing null values
print(df.isnull().sum())



#Plotting out the missing values
fig, ax = plt.subplots(figsize=(10, 6))
df.set_index('dt')['AverageTemperature'].isnull().resample('Y').sum().plot(ax=ax)
ax.set_title('Missing Temperature Values Over Time')
ax.set_ylabel('Count of Missing Values')
ax.set_xlabel('Year')
plt.show()

#It seems lot of the data seems to be missing prior the year 1870. To generalise filtering out the data prior to 1850
data_filtered = df[df['dt'].dt.year >= 1850]

# Check the missing data count after filtering
data_filtered.head(), data_filtered.isnull().sum()

#Since there are still couple of missing values in the dataset, using the technique interpolation to estimate or predict values that lie between known data points

data_filtered.loc[:, 'AverageTemperature'] = data_filtered['AverageTemperature'].interpolate(method='linear')
data_filtered.loc[:, 'AverageTemperatureUncertainty'] = data_filtered['AverageTemperatureUncertainty'].interpolate(method='linear')

# Recheck the dataset to ensure the operation was successful
data_filtered.isnull().sum(), data_filtered.head()

data_filtered

"""EDA and Visualization"""

global_avg_temp = data_filtered.groupby('dt')['AverageTemperature'].mean()

# Filter data for New Zealand
nz_avg_temp = data_filtered[data_filtered['Country'] == 'New Zealand'].groupby('dt')['AverageTemperature'].mean()

# Set Up Subplots
fig, ax = plt.subplots(1, 2, figsize=(16, 6))

# Plot Global Average Temperature
ax[0].plot(global_avg_temp.index, global_avg_temp, label='Global Average Temperature', color='orange')
ax[0].set_title('Global Average Temperature Over Time')
ax[0].set_xlabel('Year')
ax[0].set_ylabel('Average Temperature (째C)')
ax[0].legend()
ax[0].grid(True)

# Plot New Zealand Temperature Trends
ax[1].plot(nz_avg_temp.index, nz_avg_temp, label='New Zealand', color='blue')
ax[1].set_title('Temperature Trends in New Zealand')
ax[1].set_xlabel('Year')
ax[1].set_ylabel('Average Temperature (째C)')
ax[1].legend()
ax[1].grid(True)

plt.tight_layout()
plt.show()



#Calculating statistical methods mean, median, std, variance etc of global temperatures and NZ average temperature
print(global_avg_temp.describe())

print(nz_avg_temp.describe())

#Desribing correlation between the features
data_filtered[['AverageTemperature','AverageTemperatureUncertainty']].corr()

#Desribing the info among the features

data_filtered.info()

"""Regression"""

#Preparing the data
X = np.array(data_filtered['dt'].dt.year).reshape(-1, 1)  #feature
Y = data_filtered['AverageTemperature'].values #target

# Spliting the data into training and testing

from sklearn.model_selection import train_test_split
X_train, X_test,Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=20)

#Here the test size = 0.2 means that the data is split into 80:20 ratio of training and testing

print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

# Implementing the Linear Regression Model on the data
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train, Y_train)


print(f"Coefficient: {regressor.coef_[0]}")
print(f"Intercept: {regressor.intercept_}")

Y_pred = regressor.predict(X_test)
Y_pred = pd.DataFrame(Y_pred, columns=['PredictedAverageTemperature'])
Y_pred

df_pred = pd.DataFrame(columns=['Actual', 'Pred'])

# Assigning actual and predicted values to the DataFrame
df_pred['Actual'] = Y_test
df_pred['Pred'] = Y_pred

# Displaying the DataFrame
print(df_pred)

#Determining the mean errors and r2 score of the test and predict
from sklearn import metrics
from sklearn.metrics import r2_score
print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, Y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, Y_pred)))
print('r2 Score:', r2_score(Y_test, Y_pred))

"""Visualizing the predicted values"""

# Filter data within the year range and ensure no NaN values in 'AverageTemperature' and 'AverageTemperatureUncertainty'
data_reg = data_filtered[(data_filtered['dt'].dt.year >= 1850) & (data_filtered['dt'].dt.year <= 2012)]
data_reg = data_reg.dropna(subset=['AverageTemperature', 'AverageTemperatureUncertainty'])

# Calculate yearly averages and uncertainty
yearly_data = data_reg.groupby(data_reg['dt'].dt.year).agg({
    'AverageTemperature': 'mean',
    'AverageTemperatureUncertainty': 'mean'
}).reset_index()
yearly_data.rename(columns={'dt': 'Year', 'AverageTemperature': 'YearlyAverageTemp',
                            'AverageTemperatureUncertainty': 'YearlyUncertainty'}, inplace=True)

# Prepare the data for regression
X = yearly_data['Year'].values.reshape(-1, 1)
Y = yearly_data['YearlyAverageTemp'].values

# Create and fit the model
linear_model = LinearRegression()
linear_model.fit(X, Y)

# Generate predictions for the plot
X_plot = np.linspace(X.min(), X.max(), 300).reshape(-1, 1)
Y_plot = linear_model.predict(X_plot)

# Plotting
plt.figure(figsize=(12, 6))
plt.errorbar(X, Y, yerr=yearly_data['YearlyUncertainty'].values, fmt='o', color='blue',
             label='Yearly Average Temperatures', alpha=0.5, ecolor='lightgray', elinewidth=3, capsize=0)
plt.plot(X_plot, Y_plot, color='red', label='Regression Line')
plt.title('Yearly Average Temperature Trends (1850 - 2010) with Uncertainty')
plt.xlabel('Year')
plt.ylabel('Average Temperature (째C)')
plt.legend()
plt.grid(True)
plt.show()

unique_values = df['Country'].drop_duplicates()

# Perform value counts on the unique values
value_counts = unique_values.value_counts()

# Print the result
print(value_counts)

# Filter data within the year range and ensure no NaN values in 'AverageTemperature' and 'AverageTemperatureUncertainty'
data_reg = data_filtered[(data_filtered['dt'].dt.year >= 1850) & (data_filtered['dt'].dt.year <= 2012)]
data_reg = data_reg.dropna(subset=['AverageTemperature', 'AverageTemperatureUncertainty'])
nz_data = data_filtered[data_filtered['Country'] == 'New Zealand']
# Calculate yearly averages and uncertainty for New Zealand
nz_yearly_data = nz_data.groupby(nz_data['dt'].dt.year).agg({
    'AverageTemperature': 'mean',
    'AverageTemperatureUncertainty': 'mean'
}).reset_index()
nz_yearly_data.rename(columns={'dt': 'Year', 'AverageTemperature': 'NZ_YearlyAverageTemp',
                               'AverageTemperatureUncertainty': 'NZ_YearlyUncertainty'}, inplace=True)
# Prepare the data for regression
X = nz_yearly_data['Year'].values.reshape(-1, 1)
Y = nz_yearly_data['NZ_YearlyAverageTemp'].values

# Create and fit the model
linear_model = LinearRegression()
linear_model.fit(X, Y)

# Generate predictions for the plot
X_plot = np.linspace(X.min(), X.max(), 300).reshape(-1, 1)
Y_plot = linear_model.predict(X_plot)

# Plotting
plt.figure(figsize=(12, 6))
plt.errorbar(X, Y, yerr=nz_yearly_data['NZ_YearlyUncertainty'].values, fmt='o', color='blue',
             label='Yearly Average Temperatures', alpha=0.5, ecolor='lightgray', elinewidth=3, capsize=0)
plt.plot(X_plot, Y_plot, color='red', label='Regression Line')
plt.title('New Zealand Yearly Average Temperature Trends (1850 - 2012) with Uncertainty')
plt.xlabel('Year')
plt.ylabel('Average Temperature (째C)')
plt.legend()
plt.grid(True)
plt.show()

print(f"Coefficient: {linear_model.coef_[0]}")
print(f"Intercept: {linear_model.intercept_}")

